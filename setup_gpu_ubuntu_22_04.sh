#!/bin/bash
# setup_gpu_ubuntu_22_04.sh - Robust GPU setup for image-stitcher with guaranteed satisfaction
# Handles common issues and ensures proper installation

set -e

# Color codes
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# Configuration - Pinned versions for image-stitcher registration module
CONDA_ENV_NAME="image-stitcher"
REQUIRED_NUMPY_VERSION="1.26.4"  # Match your environment.yml
CUPY_PACKAGE="cupy-cuda12x"
CUDA_VERSION="12.2"  # Compatible with Driver 535.x

# Script directory
readonly script_dir="$(dirname "$(realpath -- "${BASH_SOURCE[0]}")")"
LOG_FILE="${script_dir}/gpu_setup_$(date +%Y%m%d_%H%M%S).log"

# Logging function
log() {
    echo "$1" | tee -a "$LOG_FILE"
}

print_status() {
    local status=$1
    local message=$2
    
    case $status in
        "ERROR")
            log -e "${RED}[ERROR]${NC} $message"
            ;;
        "SUCCESS")
            log -e "${GREEN}[SUCCESS]${NC} $message"
            ;;
        "WARNING")
            log -e "${YELLOW}[WARNING]${NC} $message"
            ;;
        "INFO")
            log -e "${BLUE}[INFO]${NC} $message"
            ;;
        "TEST")
            log -e "${GREEN}[TEST]${NC} $message"
            ;;
    esac
}

# Cleanup function
cleanup_failed_install() {
    print_status "INFO" "Cleaning up failed installation..."
    
    # Activate conda env
    eval "$(conda shell.bash hook)"
    conda activate "${CONDA_ENV_NAME}"
    
    # Remove any cupy installations
    pip uninstall -y cupy cupy-cuda11x cupy-cuda12x 2>/dev/null || true
    
    # Restore numpy to correct version
    pip install --force-reinstall "numpy==${REQUIRED_NUMPY_VERSION}" >/dev/null 2>&1
}

# Check prerequisites
check_prerequisites() {
    print_status "INFO" "Checking prerequisites..."
    
    # Check conda
    if ! command -v conda >/dev/null 2>&1; then
        print_status "ERROR" "Conda not found. Please run setup_ubuntu_22_04.sh first"
        return 1
    fi
    
    # Check conda environment
    if ! conda info --envs | grep -q "^${CONDA_ENV_NAME} "; then
        print_status "ERROR" "Conda environment '${CONDA_ENV_NAME}' not found"
        print_status "ERROR" "Please run: ./setup_ubuntu_22_04.sh"
        return 1
    fi
    
    # Check GPU
    if ! command -v nvidia-smi &> /dev/null; then
        print_status "ERROR" "NVIDIA drivers not found"
        print_status "INFO" "To install drivers:"
        print_status "INFO" "  sudo apt update"
        print_status "INFO" "  sudo apt install nvidia-driver-535"
        print_status "INFO" "  sudo reboot"
        return 1
    fi
    
    # Get GPU info
    local gpu_name=$(nvidia-smi --query-gpu=name --format=csv,noheader 2>/dev/null | head -n1)
    local driver_version=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader 2>/dev/null | head -n1)
    
    if [[ -z "$gpu_name" ]]; then
        print_status "ERROR" "No NVIDIA GPU detected"
        return 1
    fi
    
    print_status "SUCCESS" "Found GPU: $gpu_name"
    print_status "SUCCESS" "Driver version: $driver_version"
    
    # Check driver version for CUDA 12 support
    local driver_major=$(echo "$driver_version" | cut -d. -f1)
    if [[ "$driver_major" -lt 525 ]]; then
        print_status "ERROR" "Driver $driver_version is too old for CUDA 12"
        print_status "ERROR" "Please update to driver 525 or newer"
        return 1
    fi
    
    return 0
}

# Install CuPy properly
install_cupy() {
    print_status "INFO" "Installing CuPy in conda environment..."
    
    # Activate conda environment
    eval "$(conda shell.bash hook)"
    conda activate "${CONDA_ENV_NAME}"
    
    # Show environment info
    print_status "INFO" "Using Python: $(which python)"
    print_status "INFO" "Environment: $CONDA_PREFIX"
    
    # Clean up any existing installations
    print_status "INFO" "Removing any existing CuPy installations..."
    pip uninstall -y cupy cupy-cuda11x cupy-cuda12x 2>/dev/null || true
    
    # Pin numpy version to avoid conflicts
    print_status "INFO" "Ensuring compatible NumPy version..."
    pip install --force-reinstall "numpy==${REQUIRED_NUMPY_VERSION}"
    
    # Install CuPy with specific pip options to ensure it goes to conda env
    print_status "INFO" "Installing ${CUPY_PACKAGE}..."
    
    # Use --no-deps first to install just CuPy
    if ! pip install --no-deps --force-reinstall ${CUPY_PACKAGE}; then
        print_status "ERROR" "Failed to install CuPy"
        return 1
    fi
    
    # Then install dependencies separately
    print_status "INFO" "Installing CuPy dependencies..."
    pip install fastrlock
    
    print_status "SUCCESS" "CuPy installation completed"
    return 0
}

# Install CUDA toolkit automatically if needed
install_cuda_toolkit() {
    print_status "INFO" "Installing CUDA toolkit ${CUDA_VERSION} for image-stitcher registration module..."
    
    # Install via conda using both conda-forge and nvidia channels
    if conda install -c conda-forge -c nvidia "cuda-toolkit=${CUDA_VERSION}" -y; then
        print_status "SUCCESS" "CUDA toolkit ${CUDA_VERSION} installed successfully"
        
        # Set CUDA environment variables for CuPy compilation
        export CUDA_HOME="$CONDA_PREFIX"
        export CUDA_PATH="$CONDA_PREFIX"
        export CUDA_ROOT="$CONDA_PREFIX"
        export CPATH="$CONDA_PREFIX/targets/x86_64-linux/include:$CPATH"
        export LIBRARY_PATH="$CONDA_PREFIX/targets/x86_64-linux/lib:$LIBRARY_PATH"
        export LD_LIBRARY_PATH="$CONDA_PREFIX/targets/x86_64-linux/lib:$LD_LIBRARY_PATH"
        print_status "INFO" "Set CUDA_HOME to: $CUDA_HOME"
        print_status "INFO" "Set CPATH to include CUDA headers: $CONDA_PREFIX/targets/x86_64-linux/include"
        
        return 0
    else
        print_status "WARNING" "Failed to install exact version ${CUDA_VERSION}, trying latest compatible version..."
        # Try installing the latest available 12.2.x version
        if conda install -c conda-forge -c nvidia "cuda-toolkit=12.2.*" -y; then
            print_status "SUCCESS" "CUDA toolkit 12.2.x installed successfully"
            
            # Set CUDA environment variables for CuPy compilation
            export CUDA_HOME="$CONDA_PREFIX"
            export CUDA_PATH="$CONDA_PREFIX"
            export CUDA_ROOT="$CONDA_PREFIX"
            export CPATH="$CONDA_PREFIX/targets/x86_64-linux/include:$CPATH"
            export LIBRARY_PATH="$CONDA_PREFIX/targets/x86_64-linux/lib:$LIBRARY_PATH"
            export LD_LIBRARY_PATH="$CONDA_PREFIX/targets/x86_64-linux/lib:$LD_LIBRARY_PATH"
            print_status "INFO" "Set CUDA_HOME to: $CUDA_HOME"
            print_status "INFO" "Set CPATH to include CUDA headers: $CONDA_PREFIX/targets/x86_64-linux/include"
            
            return 0
        else
            print_status "ERROR" "Failed to install CUDA toolkit via conda"
            return 1
        fi
    fi
}

# Fix CuPy header issues automatically
fix_cupy_headers() {
    print_status "INFO" "Fixing CuPy header paths for kernel compilation..."
    
    local cupy_cuda_dir="$CONDA_PREFIX/lib/python3.10/site-packages/cupy/_core/include/cupy/_cuda"
    local system_cuda_headers="$CONDA_PREFIX/targets/x86_64-linux/include"
    
    # Check if system CUDA headers exist
    if [[ ! -d "$system_cuda_headers" ]]; then
        print_status "ERROR" "CUDA headers not found at $system_cuda_headers"
        return 1
    fi
    
    # Find CuPy's CUDA version directories and fix missing headers
    for cuda_version_dir in "$cupy_cuda_dir"/cuda-*; do
        if [[ -d "$cuda_version_dir" ]]; then
            local version_name=$(basename "$cuda_version_dir")
            print_status "INFO" "Checking headers in $version_name..."
            
            # Copy missing essential headers
            local essential_headers=(
                "vector_types.h"
                "vector_functions.h" 
                "vector_functions.hpp"
                "builtin_types.h"
                "device_types.h"
                "device_functions.h"
                "device_launch_parameters.h"
                "device_atomic_functions.h"
                "device_atomic_functions.hpp"
                "device_double_functions.h"
                "driver_types.h"
                "driver_functions.h"
            )
            
            for header in "${essential_headers[@]}"; do
                if [[ -f "$system_cuda_headers/$header" ]] && [[ ! -f "$cuda_version_dir/$header" ]]; then
                    cp "$system_cuda_headers/$header" "$cuda_version_dir/"
                    print_status "INFO" "Copied $header to $version_name"
                fi
            done
        fi
    done
    
    print_status "SUCCESS" "CuPy headers fixed"
    return 0
}

# Run comprehensive GPU tests
run_gpu_tests() {
    print_status "INFO" "Running GPU tests..."
    
    # Activate environment
    eval "$(conda shell.bash hook)"
    conda activate "${CONDA_ENV_NAME}"
    
    # Test 1: Import test
    print_status "TEST" "Testing CuPy import..."
    if ! conda run -n ${CONDA_ENV_NAME} python -c "import cupy; print(f'  CuPy version: {cupy.__version__}')" 2>&1; then
        print_status "ERROR" "Failed to import CuPy"
        return 1
    fi
    
    # Test 2: CUDA runtime
    print_status "TEST" "Checking CUDA runtime..."
    if ! conda run -n ${CONDA_ENV_NAME} python -c "
import cupy
rt = cupy.cuda.runtime.runtimeGetVersion()
print(f'  CUDA runtime: {rt//1000}.{(rt%1000)//10}')
" 2>&1; then
        print_status "ERROR" "Failed to get CUDA runtime"
        return 1
    fi
    
    # Test 3: GPU device info
    print_status "TEST" "Getting GPU device info..."
    if ! conda run -n ${CONDA_ENV_NAME} python -c "
import cupy
device = cupy.cuda.Device()
props = cupy.cuda.runtime.getDeviceProperties(device.id)
print(f'  GPU device: {props[\"name\"].decode()}')
free, total = device.mem_info
print(f'  GPU memory: {free/1024**3:.1f}GB free / {total/1024**3:.1f}GB total')
" 2>&1; then
        print_status "ERROR" "Failed to get GPU info"
        return 1
    fi
    
    # Test 4: Simple computation with proper environment
    print_status "TEST" "Testing GPU computation with environment variables..."
    
    # Export environment variables for this session
    export CUDA_HOME="$CONDA_PREFIX"
    export CUDA_PATH="$CONDA_PREFIX"
    export CUDA_ROOT="$CONDA_PREFIX"
    export CPATH="$CONDA_PREFIX/targets/x86_64-linux/include:$CPATH"
    export LIBRARY_PATH="$CONDA_PREFIX/targets/x86_64-linux/lib:$LIBRARY_PATH"
    export LD_LIBRARY_PATH="$CONDA_PREFIX/targets/x86_64-linux/lib:$LD_LIBRARY_PATH"
    
    if ! python -c "
import cupy as cp
import numpy as np

# First test: Can we create arrays on GPU?
try:
    x_cpu = np.random.random((100, 100)).astype(np.float32)
    x_gpu = cp.asarray(x_cpu)
    print('  GPU array creation: PASSED')
except Exception as e:
    print(f'  GPU array creation: FAILED - {e}')
    raise

# Second test: Can we do basic operations?
try:
    # Try a simple operation that doesn't require kernel compilation
    result = cp.asnumpy(x_gpu)
    print('  GPU-CPU transfer: PASSED')
except Exception as e:
    print(f'  GPU-CPU transfer: FAILED - {e}')
    raise

# Third test: Can we do basic arithmetic (requires NVRTC)?
try:
    y_gpu = x_gpu + x_gpu  # Simple addition
    result = cp.asnumpy(y_gpu)
    print('  Basic arithmetic: PASSED')
    
    # Fourth test: Try FFT if basic operations work
    try:
        large_gpu = cp.asarray(np.random.random((1000, 1000)).astype(np.float32))
        fft_result = cp.fft.fft2(large_gpu)
        print('  FFT computation: PASSED')
    except ImportError as e:
        if 'libcufft' in str(e):
            print('  FFT libraries not available (this is OK for basic use)')
            # Use basic math instead
            math_result = large_gpu * 2.0 + 1.0
            math_result = cp.sum(math_result)
            print('  Alternative math computation: PASSED')
        else:
            raise
            
except RuntimeError as e:
    if 'libnvrtc' in str(e):
        print('  Basic arithmetic: FAILED - Missing NVIDIA Runtime Compiler')
        print('  CuPy requires CUDA toolkit for kernel compilation')
        raise
    else:
        raise

print('  GPU computation tests: COMPLETED')
" 2>&1; then
        print_status "ERROR" "GPU computation failed - Missing CUDA libraries"
        print_status "INFO" "CuPy needs CUDA runtime libraries to function properly"
        return 1
    fi
    
    # Test 5: Performance comparison
    print_status "TEST" "Comparing GPU vs CPU performance..."
    python -c "
import time
import numpy as np
import cupy as cp

size = 2048
iterations = 10

# Check if FFT is available
try:
    # Test if cuFFT is available
    test_array = cp.random.random((10, 10), dtype=cp.float32)
    _ = cp.fft.fft2(test_array)
    fft_available = True
    operation_name = 'FFT'
except ImportError:
    fft_available = False
    operation_name = 'Matrix multiplication'

if fft_available:
    # CPU timing - FFT
    cpu_data = np.random.random((size, size)).astype(np.float32)
    start = time.time()
    for _ in range(iterations):
        _ = np.fft.fft2(cpu_data)
    cpu_time = time.time() - start
    
    # GPU timing - FFT
    gpu_data = cp.asarray(cpu_data)
    cp.cuda.Stream.null.synchronize()
    start = time.time()
    for _ in range(iterations):
        _ = cp.fft.fft2(gpu_data)
    cp.cuda.Stream.null.synchronize()
    gpu_time = time.time() - start
else:
    # Fallback to matrix multiplication
    cpu_data = np.random.random((size//2, size//2)).astype(np.float32)
    start = time.time()
    for _ in range(iterations):
        _ = np.dot(cpu_data, cpu_data.T)
    cpu_time = time.time() - start
    
    # GPU timing - matrix multiplication
    gpu_data = cp.asarray(cpu_data)
    cp.cuda.Stream.null.synchronize()
    start = time.time()
    for _ in range(iterations):
        _ = cp.dot(gpu_data, gpu_data.T)
    cp.cuda.Stream.null.synchronize()
    gpu_time = time.time() - start

speedup = cpu_time / gpu_time
print(f'  Operation: {operation_name}')
print(f'  CPU time: {cpu_time:.3f}s')
print(f'  GPU time: {gpu_time:.3f}s')
print(f'  Speedup: {speedup:.1f}x')

if speedup > 1.5:
    print('  Performance: EXCELLENT')
else:
    print('  Performance: GPU may not be fully utilized')
" 2>&1 || print_status "WARNING" "Performance test incomplete"
    
    print_status "SUCCESS" "All GPU tests passed!"
    return 0
}

# Create integration test
create_integration_test() {
    local test_file="${script_dir}/test_gpu_integration.py"
    
    cat > "$test_file" << 'EOF'
#!/usr/bin/env python
"""Integration test for GPU-accelerated image stitching"""

import sys
import numpy as np

try:
    import cupy as cp
    GPU_AVAILABLE = True
except ImportError:
    GPU_AVAILABLE = False
    print("CuPy not available - GPU support not installed")
    sys.exit(1)

def test_stitching_operations():
    """Test operations commonly used in image stitching"""
    print("\nTesting image stitching operations on GPU...")
    
    # Simulate image data
    image_size = (1024, 1024)
    tile1 = np.random.random(image_size).astype(np.float32)
    tile2 = np.random.random(image_size).astype(np.float32)
    
    # Convert to GPU
    tile1_gpu = cp.asarray(tile1)
    tile2_gpu = cp.asarray(tile2)
    
    # Check if FFT is available
    try:
        test_fft = cp.fft.fft2(cp.random.random((10, 10), dtype=cp.float32))
        fft_available = True
    except ImportError:
        fft_available = False
        print("  Note: FFT libraries not available, using alternative tests")
    
    if fft_available:
        # Test 1: FFT-based phase correlation (common in stitching)
        print("- Testing phase correlation...")
        fft1 = cp.fft.fft2(tile1_gpu)
        fft2 = cp.fft.fft2(tile2_gpu)
        cross_power = fft1 * cp.conj(fft2)
        cross_power /= cp.abs(cross_power) + 1e-10
        correlation = cp.fft.ifft2(cross_power)
        peak = cp.unravel_index(cp.argmax(cp.abs(correlation)), correlation.shape)
        print(f"  Peak found at: {peak}")
        
        # Test 3: Large array FFT
        print("- Testing large FFT operations...")
        large_image = cp.random.random((2048, 2048), dtype=cp.float32)
        result = cp.fft.fft2(large_image)
        cp.cuda.Stream.null.synchronize()
        print(f"  Large FFT completed: {result.shape}")
    else:
        # Alternative tests without FFT
        print("- Testing correlation without FFT...")
        # Simple correlation using convolution-like operations
        correlation = cp.zeros_like(tile1_gpu)
        for i in range(0, min(100, image_size[0]), 10):
            for j in range(0, min(100, image_size[1]), 10):
                correlation[i, j] = cp.sum(tile1_gpu[i:i+10, j:j+10] * tile2_gpu[i:i+10, j:j+10])
        peak = cp.unravel_index(cp.argmax(correlation), correlation.shape)
        print(f"  Peak found at: {peak}")
        
        # Test 3: Large array operations
        print("- Testing large array operations...")
        large_image = cp.random.random((2048, 2048), dtype=cp.float32)
        result = cp.sum(large_image, axis=1)
        cp.cuda.Stream.null.synchronize()
        print(f"  Large array reduction completed: {result.shape}")
    
    # Test 2: Image blending (always available)
    print("- Testing image blending...")
    alpha = cp.linspace(0, 1, image_size[1], dtype=cp.float32)
    alpha = alpha[cp.newaxis, :]
    blended = tile1_gpu * (1 - alpha) + tile2_gpu * alpha
    print(f"  Blended shape: {blended.shape}")
    
    print("\nâœ“ All stitching operations successful on GPU!")
    return True

if __name__ == "__main__":
    if test_stitching_operations():
        print("\nGPU integration test PASSED")
        sys.exit(0)
    else:
        print("\nGPU integration test FAILED")
        sys.exit(1)
EOF
    
    chmod +x "$test_file"
    print_status "SUCCESS" "Created integration test: test_gpu_integration.py"
}

# Main installation flow
main() {
    log "=== Robust GPU Setup for Image Stitcher ==="
    log "Starting at: $(date)"
    log "Log file: $LOG_FILE"
    echo
    
    # Activate conda environment FIRST before any installations
    print_status "INFO" "Activating conda environment: ${CONDA_ENV_NAME}"
    eval "$(conda shell.bash hook)"
    if ! conda activate "${CONDA_ENV_NAME}" 2>/dev/null; then
        print_status "ERROR" "Failed to activate conda environment: ${CONDA_ENV_NAME}"
        print_status "INFO" "Please create the environment first with: conda env create -f environment.yml"
        exit 1
    fi
    print_status "SUCCESS" "Activated conda environment: ${CONDA_ENV_NAME}"
    print_status "INFO" "Using Python: $(which python)"
    print_status "INFO" "Environment: $CONDA_PREFIX"
    
    # Set CUDA environment variables if CUDA toolkit is already installed
    if [[ -d "$CONDA_PREFIX/targets/x86_64-linux/include" ]]; then
        export CUDA_HOME="$CONDA_PREFIX"
        export CUDA_PATH="$CONDA_PREFIX"
        export CUDA_ROOT="$CONDA_PREFIX"
        export CPATH="$CONDA_PREFIX/targets/x86_64-linux/include:$CPATH"
        export LIBRARY_PATH="$CONDA_PREFIX/targets/x86_64-linux/lib:$LIBRARY_PATH"
        export LD_LIBRARY_PATH="$CONDA_PREFIX/targets/x86_64-linux/lib:$LD_LIBRARY_PATH"
        print_status "INFO" "Found existing CUDA installation, set CUDA_HOME to: $CUDA_HOME"
        print_status "INFO" "Set CPATH to include CUDA headers: $CONDA_PREFIX/targets/x86_64-linux/include"
    fi
    echo
    
    # Check prerequisites
    if ! check_prerequisites; then
        print_status "ERROR" "Prerequisites check failed"
        exit 1
    fi
    
    # Install CuPy
    if ! install_cupy; then
        print_status "ERROR" "CuPy installation failed"
        cleanup_failed_install
        exit 1
    fi
    
    # Fix headers if CUDA is already installed
    if [[ -d "$CONDA_PREFIX/targets/x86_64-linux/include" ]]; then
        print_status "INFO" "CUDA toolkit detected, fixing CuPy headers..."
        fix_cupy_headers
    fi
    
    # Run tests
    if ! run_gpu_tests; then
        print_status "WARNING" "Initial GPU tests failed - likely missing CUDA libraries"
        print_status "INFO" "Installing CUDA toolkit ${CUDA_VERSION} for compatibility with Driver 535.x..."
        
        # Install CUDA toolkit
        if install_cuda_toolkit; then
            print_status "INFO" "Fixing CuPy headers after CUDA toolkit installation..."
            if fix_cupy_headers; then
                print_status "INFO" "Retrying GPU tests after CUDA toolkit installation and header fixes..."
                if run_gpu_tests; then
                    print_status "SUCCESS" "GPU setup successful after installing CUDA toolkit!"
                else
                    print_status "ERROR" "GPU tests still failing after CUDA toolkit installation and header fixes"
                    print_status "INFO" "Attempting cleanup and reinstall..."
                    cleanup_failed_install
                    
                    # Try once more
                    if install_cupy && fix_cupy_headers && run_gpu_tests; then
                        print_status "SUCCESS" "Recovery successful!"
                    else
                        print_status "ERROR" "GPU setup failed. Check $LOG_FILE for details"
                        exit 1
                    fi
                fi
            else
                print_status "ERROR" "Failed to fix CuPy headers"
                exit 1
            fi
        else
            print_status "ERROR" "Failed to install CUDA toolkit"
            exit 1
        fi
    fi
    
    # Create integration test
    create_integration_test
    
    # Check CUDA library availability and provide guidance
    echo
    print_status "INFO" "Checking CUDA library availability..."
    
    # Test basic CuPy functionality
    if conda run -n ${CONDA_ENV_NAME} python -c "import cupy; x = cupy.array([1,2,3]); y = x + x; print('Basic operations work')" 2>/dev/null; then
        print_status "SUCCESS" "Basic CUDA operations are working!"
        
        # Test FFT specifically
        if conda run -n ${CONDA_ENV_NAME} python -c "import cupy; cupy.fft.fft2(cupy.random.random((10, 10)))" 2>/dev/null; then
            print_status "SUCCESS" "FFT libraries are also available!"
        else
            print_status "WARNING" "cuFFT library not found - FFT operations will be limited"
            echo
            echo "=== Optional: Installing cuFFT ==="
            echo "For full FFT support, install CUDA toolkit:"
            echo
            echo "  # Option 1: Install via conda (CUDA 12.2 for Driver 535.x)"
            echo "  conda install -c conda-forge -c nvidia cuda-toolkit=12.2"
            echo
            echo "Note: Basic GPU operations work fine. Image stitching can use alternative methods."
        fi
    else
        print_status "ERROR" "Basic CUDA operations are not working!"
        echo
        echo "=== REQUIRED: Installing CUDA Toolkit ==="
        echo "CuPy requires CUDA runtime libraries. Install with:"
        echo
        echo "  # Option 1: Install full CUDA toolkit via conda (recommended for Driver 535.x)"
        echo "  conda install -c conda-forge -c nvidia cuda-toolkit=12.2"
        echo
        echo "  # Option 2: Install system CUDA toolkit 12.2"
        echo "  wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb"
        echo "  sudo dpkg -i cuda-keyring_1.1-1_all.deb"
        echo "  sudo apt-get update"
        echo "  sudo apt-get -y install cuda-toolkit-12-2"
        echo
        echo "  # Option 3: Install minimal CUDA runtime (alternative)"
        echo "  conda install -c conda-forge -c nvidia cuda-runtime=12.2"
        echo
        print_status "WARNING" "CuPy will not work properly without CUDA libraries!"
        return 1
    fi

    # Success summary
    echo
    print_status "SUCCESS" "GPU setup completed successfully! ðŸŽ‰"
    echo
    echo "=== Configuration Summary ==="
    echo "  CUDA Version: ${CUDA_VERSION} (compatible with Driver 535.x)"
    echo "  NumPy Version: ${REQUIRED_NUMPY_VERSION}"
    echo "  CuPy Package: ${CUPY_PACKAGE}"
    echo "  Environment: ${CONDA_ENV_NAME}"
    echo
    echo "=== Quick Verification ==="
    echo "Run this command to verify GPU is working:"
    echo
    echo "  conda activate ${CONDA_ENV_NAME} && python -c 'import cupy; device = cupy.cuda.Device(); props = cupy.cuda.runtime.getDeviceProperties(device.id); print(\"GPU:\", props[\"name\"].decode())'"
    echo
    echo "=== Integration Test ==="
    echo "Test GPU with stitching operations:"
    echo
    echo "  conda activate ${CONDA_ENV_NAME} && python test_gpu_integration.py"
    echo
    echo "=== Using GPU in Your Registration Module ==="
    echo "Your image_stitcher/registration module is now ready to use GPU acceleration:"
    echo
    echo "  import cupy as cp  # Instead of numpy as np"
    echo "  # Use cp.array() instead of np.array()"
    echo "  # All operations work the same but run on GPU"
    echo
    print_status "SUCCESS" "Setup complete! Your GPU is ready for image-stitcher registration module."
}

# Run main
main "$@"
